knitr::opts_chunk$set(fig.align = "center", message = FALSE, warning = FALSE)
options(warn = -1)
suppressMessages(library(caret))
suppressMessages(library(nnet))
suppressMessages(library(tree))
suppressMessages(library(ISLR))
suppressMessages(library(randomForest))
suppressMessages(library(mlbench))
suppressMessages(library(MASS))
suppressMessages(library(e1071))
suppressMessages(library(corrplot))
suppressMessages(library(kableExtra))
#These two libraries are to be commented in Windows
suppressMessages(library(parallel))
suppressMessages(library(doParallel))
cluster =  makeCluster(detectCores() - 1) # convention to leave 1 core for OS
registerDoParallel(cluster)
seed = 12345
ClassAcc = function(predicted,actual)
{
return(mean(predicted == actual))
}
get_best_result = function(caret_fit) {
best = which(rownames(caret_fit$results) == rownames(caret_fit$bestTune))
best_result = caret_fit$results[best, ]
rownames(best_result) = NULL
best_result
}
data_HR = read.csv('HR_comma_sep.csv')
factor_cols = c('Work_accident', 'left', 'promotion_last_5years', 'sales', 'salary')
data_HR[,factor_cols] = data.frame(apply(data_HR[factor_cols], 2, as.factor))
colnames(data_HR)= c("satisfaction","evaluation","projects","hours","years","accident",
"left","promotion","sales","salary")
train_index = sample(1:nrow(data_HR), size = round(0.5 * nrow(data_HR)))
train_HR = data_HR[train_index, ]
test_HR = data_HR[-train_index, ]
glm = glm(left ~ ., train_HR, family = "binomial")
prob = predict(glm,newdata = test_HR,type = 'response')
pred = ifelse(prob > 0.5, 1, 0)
acc_glm = ClassAcc(pred,test_HR$left)
acc_glm
#Scaled Result for KNN
set.seed(seed)
knn_scale = train(
left ~ .,
data = train_HR,
method = "knn",
trControl = trainControl(method = "cv", number = 5),
preProcess = c("center", "scale")
)
cv_knn_scale = get_best_result(knn_scale)$Accuracy
acc_knn_scale = ClassAcc(
predict(knn_scale, test_HR),
test_HR$left
)
#Unscaled Result for KNN
set.seed(seed)
knn_unscale = train(
left ~ .,
data = train_HR,
method = "knn",
trControl = trainControl(method = "cv", number = 5)
)
cv_knn_unscale = get_best_result(knn_unscale)$Accuracy
acc_knn_unscale = ClassAcc(
predict(knn_unscale, test_HR),
test_HR$left
)
c(cv_knn_scale,cv_knn_unscale)
c(acc_knn_scale,acc_knn_unscale)
flat= c(1,1)/2
lda_norm = lda(left ~ ., train_HR)
acc_lda_norm = ClassAcc(predict(lda_norm, test_HR)$class, test_HR$left)
#LDA (with Priors estimated from data)
lda_flat = lda(left ~ ., train_HR,prior=flat)
acc_lda_flat = ClassAcc(predict(lda_flat, test_HR)$class, test_HR$left)
#LDA with Flat Prior
c(acc_lda_norm,acc_lda_flat)
qda_norm = qda(left ~ ., train_HR)
acc_qda_norm = ClassAcc(predict(qda_norm, test_HR)$class, test_HR$left)
#QDA (with Priors estimated from data)
qda_flat = qda(left ~ ., train_HR, prior=flat)
acc_qda_flat = ClassAcc(predict(qda_flat, test_HR)$class, test_HR$left)
#QDA (with Flat Prior)
c(acc_qda_norm,acc_qda_flat)
set.seed(seed)
lin_grid = expand.grid(C = c(2 ^ (-5:5)))
if (FALSE){
svmLinear_tuned = train(
left~.,
data = train_HR,
method = 'svmLinear',
trControl = trainControl(method = "cv", number = 5)
)
}
#Large Cross Validation Model.
#Takes A Long Time to Build So we Saved it and Call it whenever Needed.
#You are welcomed to see if the model trained
#is the same as the model we loaded.
svmLinear_tuned= readRDS("svmLinear.rds")
pred = predict(svmLinear_tuned,test_HR)
acc_svmLinear = ClassAcc(pred,test_HR$left)
acc_svmLinear
set.seed(seed)
if (FALSE){
svmPoly_tuned = train(
left~.,
data = train_HR,
method = 'svmPoly',
trControl = trainControl(method = "cv", number = 5)
)
}
svmPoly_tuned = readRDS("svmPoly.rds")
#Large Cross Validation Model.
#Takes A Long Time to Build So we Saved it and Call it whenever Needed.
#You are welcomed to see if the model trained
#is the same as the model we loaded.
pred = predict(svmPoly_tuned,test_HR)
acc_svmPoly = ClassAcc(pred,test_HR$left)
acc_svmPoly
set.seed(seed)
if (FALSE){
svmRadial_tuned = train(
left~.,
data = train_HR,
method = 'svmRadial',
trControl = trainControl(method = "cv", number = 5)
)
}
svmRadial_tuned = readRDS("svmRadial.rds")
#Large Cross Validation Model.
#Takes A Long Time to Build So we Saved it and Call it whenever Needed.
#You are welcomed to see if the model trained
#is the same as the model we loaded.
pred = predict(svmRadial_tuned,test_HR)
acc_svmRadial = ClassAcc(pred,test_HR$left)
acc_svmRadial
exp_tree = tree(left ~ ., data = train_HR)
plot(exp_tree,type= c("uniform"))
text(exp_tree, pretty = 4)
set.seed(seed)
tunegrid = expand.grid(.mtry = c(1:10))
if (FALSE){
rf = train(left~., data=train_HR, method = 'rf', tuneGrid=tunegrid,
trConrol = trainControl(method = 'oob')
)
}
rf = readRDS("caretRF.rds")
#Large Cross Validation Model.
#Takes A Long Time to Build So we Saved it and Call it whenever Needed.
#You are welcomed to see if the model trained
#is the same as the model we loaded.
best_mtry = get_best_result(rf)$mtry
best_rf = randomForest(left ~ ., train_HR,mtry = best_mtry)
plot(rf$results$mtry,rf$results$Accuracy,pch = 19,xlab = 'Predictors used',
ylab = 'Cross Validation Accuracy'
)
best_rf = randomForest(left ~ ., train_HR,mtry = best_mtry)
pred_rf = predict(rf, newdata = test_HR)
acc_rf = ClassAcc(pred_rf,test_HR$left)
acc_rf
varImpPlot(best_rf)
set.seed(seed)
gbm_grid = expand.grid(interaction.depth = c(1, 2),
n.trees = c(500, 1000, 1500),
shrinkage = c(0.001, 0.01, 0.1),
n.minobsinnode = 10)
if (FALSE){
gbm = train(left ~ ., data = train_HR,
method = "gbm",
trControl = trainControl(method = "cv", number = 5),
verbose = FALSE,
tuneGrid = gbm_grid)
}
gbm = readRDS('gbm.rds')
#Large Cross Validation Model.
#Takes A Long Time to Build So we Saved it and Call it whenever Needed.
#You are welcomed to see if the model trained
#is the same as the model we loaded.
pred_gbm = predict(gbm, newdata = test_HR)
acc_gbm = ClassAcc(pred_gbm,test_HR$left)
acc_gbm
nb_mod = train(
left ~ .,
data = train_HR,
trControl = trainControl(method = "cv", number = 5),
method = "nb"
)
acc_nb_tuned =get_best_result(nb_mod)$Accuracy
acc_nb_tuned
accuracies = cbind(
Methods = c('KNN_scaled','KNN_unscaled'),
Accuracy = round(c(acc_knn_scale,acc_knn_unscale),4)
)
colnames(accuracies) = c("Method", "Test Accuracy")
knitr::kable(accuracies,
caption = "KNN Testing Accuracies",
booktabs = TRUE)
accuracies = cbind(
Methods = c('LDA_Normal','LDA_Flat','QDA_Normal','QDA_Flat'),
Accuracy = round(c(acc_lda_norm,acc_lda_flat,acc_qda_norm,acc_qda_flat),4)
)
colnames(accuracies) = c("Method", "Test Accuracy")
knitr::kable(accuracies,
caption = "LDA and QDA Testing Accuracies",
booktabs = TRUE)
accuracies = cbind(
Methods = c('Logistic_Reg','Naive_Bayes'),
Accuracy = round(c(acc_glm,acc_nb_tuned),4)
)
colnames(accuracies) = c("Method", "Test Accuracy")
knitr::kable(accuracies,
caption = "Logistic Regression and Naive Bayes Testing Accuracies",
booktabs = TRUE)
accuracies = cbind(
Methods = c('SVM_Linear','SVM_Poly','SVM_Radial'),
Accuracy = round(c(acc_svmLinear,acc_svmPoly,acc_svmRadial),4)
)
colnames(accuracies) = c("Method", "Test Accuracy")
knitr::kable(accuracies,
caption = "SVM Testing Accuracies",
booktabs = TRUE)
accuracies = cbind(
Methods = c('random forest','boosted tree'),
Accuracy = round(c(acc_rf,acc_gbm),4)
)
colnames(accuracies) = c("Method", "Test Accuracy")
knitr::kable(accuracies,
caption = "SVM Testing Accuracies",
booktabs = TRUE)
featurePlot(
x = train_HR[, c("satisfaction", "years", "projects", "hours", "evaluation")],
train_HR$left,
plot = "density",
scales = list(
x = list(relation = "free"),
y = list(relation = "free")
),
auto.key = list(columns = 5)
)
stopCluster(cluster)
registerDoSEQ()
accuracies = cbind(
Methods = c(
'Logistic_Reg',
'KNN_scaled',
'KNN_unscaled',
'Naive_Bayes',
'LDA_Normal',
'LDA_Flat',
'QDA_Normal',
'QDA_Flat',
'SVM_Linear',
'SVM_Poly',
'SVM_Radial',
'random forest',
'boosted tree'
),
Accuracy = round(
c(
acc_glm,
acc_knn_scale,
acc_knn_unscale,
acc_nb_tuned,
acc_lda_norm,
acc_lda_flat,
acc_qda_norm,
acc_qda_flat,
acc_svmLinear,
acc_svmPoly,
acc_svmRadial,
acc_rf,
acc_gbm
),
4
)
)
colnames(accuracies) = c("Method", "Test Accuracy")
knitr::kable(accuracies,
caption = "Testing Accuracies",
booktabs = TRUE)
